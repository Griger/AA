---
title: \textbf{Proyecto Final. Cardiotocography}
author: "Anabel Gómez Ríos y Gustavo Rivas Gervilla"
date: "16 de junio de 2016"
output: pdf_document
---

```{r}
library(caret) # para qué?
library(glmnet)
library(fields)
```


#1. Definición del problema a resolver y enfoque elegido.

En este proyecto vamos a trabajar con una base da datos algo mayor que las que hemos venido usando en las prácticas (2126 instancias con 23 atributos cada una) con el objetivo de poner en práctica los conocimientos adquiridos en la asignatura para resolver un problema de clasificación del mundo real.
  
La base de datos elegida es Cardiotocography del respositorio de bases de datos UCI la cual la podemos descargar \href{https://archive.ics.uci.edu/ml/datasets/Cardiotocography#}{\textbf{aquí}}. En esta base de datos se recogen distintas características de cardiotrogafías en las cuales se mide la frencuencia cardiaca fetal (FHR), los movimiento fetales (FM) y las contracciones uterinas (UC), obteniendo las siguientes características a partir de estos datos:

\begin{enumerate}
\item LB: punto de referencia del FHR en pulsaciones por minuto.
\item AC: aceleraciones del pulso por segundo.
\item FM: movimientos fetales por segundo.
\item UC: contracciones uterinas por segundo.
\item DL: deceleraciones suaves por segundo.
\item DS: deceleraciones fuertes por segundo.
\item DP: deceleraciones prolongadas por segundo.
\item ASTV: porcentaje de tiempo con variaciones anormales cortas del pulso.
\item MSTV: media de las variaciones anormales cortas del pulso.
\item ALTV: porcentaje de tiempo con variaciones anormales largas del pulso.
\item MLTV: media de las variaciones anormales largas del pulso.
\item Width: amplitud del histograma FHR.
\item Min: mínimo del histograma FHR.
\item Max: máximo del hisotograma FHR.
\item Nmax: número de picos en el histograma.
\item Nzeros: número de ceros en el histograma.
\item Mode: moda del histograma.
\item Mean: media del histograma.
\item Median: mediana del histograma.
\item Variance: varianza del histograma.
\item Tendency: tendencia del histograma.
\item CLASS: código del tipo de patrón del histograma FHR [1-10].
\item NSP: código del estado fetal. [1: Normal, 2: Sospechoso y 3: Patológico]
\end{enumerate}

Lo que queremos es emplear estos datos para poder predecir ante una nueva cardiotocografía si el estado del feto es normal, sospecho o patológico, es decir, vamos a predecir la variable NSP con el resto. Además, vamos a hacer la clasificación también según la variable CLASS, puesto que también es una de las "preguntas" en la base de datos.  

El enfoque elegido por tanto es hacer clasificación multiclase para clasificar nuevos datos según dos variables (por separado), una que tiene 3 clases y otra que tiene 10.

```{r}
datos <- read.csv("datos.csv")
```

#2. Codificación de los datos de entranda para hacerlos útiles a los algoritmos.

Nuestra base de datos estaba contenida en una hoja de cálculo. Para poder usarla dentro de R lo que hemos hecho es generar un CSV con los datos previamente formateados puesto que hemos tenido que cambiar el formato decimal de algunas columnas para que fuese el que emplea R. Además en el fichero original aparecían más variables como la fehca y el tiempo de inicio y fin de la cardiotocografía las cuales no hemos considerado relevantes para el estudio por lo que no están presententes en el CSV.

#3. Valoración del interés de las variables para el problema y selección de un subconjunto en su caso.

En primer lugar tenemos que `Width` se calcula como la diferencia entre `Max` y `Min` con lo cual suponemos que una de las tres no tendrán relevancia ya que la información aportada por ella se puede deducir de las otras dos.  

Para el resto de variables dado el poco conocimiento que tenemos en la materia no podemos saber qué factores son los que más influyen en determinar el estado del feto por tanto hemos decidido realizar un análisis de componentes principales para ver si podemos reducir el número de variables a considerar, haciendo que los algoritmos sean mÃ¡s eficientes en tiempo. La técnica que hemos usado en clase para tal propósito ha sido emplear el Lasso para obtener aquellas variables que sus coeficientes estuviesen por encima de un cierto umbral determinado por nosotros. Esto precisamente es lo que nos ha llevado a decantarnos por el PCA ya que con él podemos saber el conjunto de variables que son capaces de explicar al menos 95% de la variabilidad de los datos (aunque podemos cambiar este 95% y aumentarlo para que sea más estricto). Para saber cómo emplear PCA en R hemos consultado el enlace [2] de la bibliografía.  

Lo primero que vamos a hacer es separar los datos en las muestras de entrenamiento y test (80-20) que emplearemos a lo largo de todo el estudio. En esta ocasión como la variable a predecir no depende de la media de otras variables entonces vamos a poder realizar un particionado homogéneo de los datos para tener una distribución de las clases de cada muestra lo más uniforme posible (no corremos el riesgo de contaminar la variable con datos de test como un ocurría en prácticas).  

```{r}
set.seed(1)
# Cogemos los índices del 80% de los datos para cada clase
train_idx <- c(sample(which(datos$NSP == 1), size =
                        ceiling(0.8*sum(datos$NSP==1))),
               sample(which(datos$NSP == 2), size =
                        ceiling(0.8*sum(datos$NSP==2))),
               sample(which(datos$NSP == 3), size =
                        ceiling(0.8*sum(datos$NSP==3))))

# Hacemos el conjunto de train con estos índices
train <- datos[train_idx,]
# Hacemos el conjunto de test con todas aquellas variables que no tengan estos
# índices
test <- datos[-train_idx,]
```

```{r}
set.seed(1)
# Cogemos los índices del 80% de los datos para cada clase

train_idx <- c(sample(which(datos$CLASS == 1), size =
                        ceiling(0.8*sum(datos$CLASS==1))),
               sample(which(datos$CLASS == 2), size =
                        ceiling(0.8*sum(datos$CLASS==2))),
               sample(which(datos$CLASS == 3), size =
                        ceiling(0.8*sum(datos$CLASS==3))),
               sample(which(datos$CLASS == 4), size =
                        ceiling(0.8*sum(datos$CLASS==4))),
               sample(which(datos$CLASS == 5), size =
                        ceiling(0.8*sum(datos$CLASS==5))),
               sample(which(datos$CLASS == 6), size =
                        ceiling(0.8*sum(datos$CLASS==6))),
               sample(which(datos$CLASS == 7), size =
                        ceiling(0.8*sum(datos$CLASS==7))),
               sample(which(datos$CLASS == 8), size =
                        ceiling(0.8*sum(datos$CLASS==8))),
               sample(which(datos$CLASS == 9), size =
                        ceiling(0.8*sum(datos$CLASS==9))),
               sample(which(datos$CLASS == 10), size =
                        ceiling(0.8*sum(datos$CLASS==10))))

#train_idx <- sample(seq(1, nrow(datos)), ceiling(0.8*nrow(datos)))
# Hacemos el conjunto de train con estos índices
train10 <- datos[train_idx,]
# Hacemos el conjunto de test con todas aquellas variables que no tengan estos
# índices
test10 <- datos[-train_idx,]
```


Ahora vamos a quitar las variables `NSP` y `CLASS` de `train` y test, ya que son las salidas, y las vamos a guardar en dos vectores aparte.

```{r}
NSP.train <- train$NSP
train <- train[,-c(22,23)]
NSP.test <- test$NSP
test <- test[,-c(22,23)]

CLASS.train <- train10$CLASS
train10 <- train10[,-c(22,23)]
CLASS.test <- test10$CLASS
test10 <- test10[,-c(22,23)]
```


Vamos a hacer un `summary` sobre los datos de `train` para ver si podemos descartar alguna variable que a simple vista se vea que no va a aportar nada.

```{r}
summary(train)
summary(train10)
```

Como vemos, la variable DS tiene máximo y mínimo 0, con lo que es igual a 0 para todas las variables y por tanto no van a infuir para nuestro análisis en el conjunto de train. Lo que hacemos por tanto es quitarla de dicho conjunto.

```{r}
# Quitamos la variable DS, que ocupa la sexta columna
train <- train[,-6]
test <- test[,-6] # ESTO NO SABEMOS SI SE PUEDE HACER
train10 <- train10[,-6]
test10 <- test10[,-6]
```

Como hemos podido ver hay muchas que tienen valores cercanos a cero, pero sobre estos no podemos decir nada en claro, así que vamos a pasar a utilizar el algoritmo PCA. Para ello vamos a utilizar la función `prcomp` del paquete `stats` instalado por defecto en `R`.

El análisis de componente principales (PCA) sigue la siguiente idea: nosotros podemos tener nuestras muestran con gran multitud de características, es decir, muestras con una elevada dimensión. Ahora bien pueden darse caso en que no todas estas características tengan la misma relevancia, no aporten la misma información. Por motivos de eficiencia computacional y obtener un modelo más sencillo es claro que es bueno reducir este número de variables, y esto es lo que hace el PCA. Buscamos una representación de los datos de dimensión más baja que capture toda (o una cantidad considerable) de la información. Un dimensión es interesante en términos de cómo las observaciones varían a lo largo de dicha dimensión.

Si nuestras muestras tienen el siguiente conjunto de características $X_1, X_2, ..., X_p$ entonces primer componente principal será $Z_1 = \phi_1X_1 + ... + \phi_pX_p$ y buscamos entoncecs una combinación lineal de las características anteriores, cumpliendo que el cuadrado de los coeficientes (*loadings*) sumen uno, que maximize la varianza, es decir, que maximice $\frac{1}{n}\sum_{i = 1}^n \left( \sum_{j = 1}^p \phi_{j1}x_{ij} \right)^2$ (estamos sumoniendo que las variables tienen media cero para estos cálculos). Señalar que la condición de normalización que le imponemos a los *loadings* es para que no ganemos máxima varianza simplemente haciéndolos crecer mucho. Para calcular el resto de componente principales se hace de la misma manera restringiendo además a que no estén correlados con los anteriores; que sean ortogonales (si vemos los *loadings* como vectores) a los anteriores.

Ya hemos asumido antes que la media de cada variable es cero ya que sólo estamos interesados en la varianza y esto facilita los cálculos. Por otro lado, si no tenemos ninguna restricción que lo impida, es conveniente escalar las variables de modo que no tengan una más influencia que otra simplemente por la escala en la que está medida, por ejemplo si una variable da saltos de 1000 en 1000 y otra de 10 en 10, aunque los datos de la primera presenten menos varianza debido a la magnidtud de los datos ésta tendrá más influencia.

```{r}
pca.out <- prcomp(train, center = TRUE, scale = TRUE)
pca.out10 <- prcomp(train10, center = TRUE, scale = TRUE)
```

VENDER HUMO

```{r}
biplot(pca.out, scale = 0)
plot(pca.out, main="PCA")
summary(pca.out)
```

Como podemos ver con `summary()`, con las 14 primeras componentes principales estamos explicando un 96% de los datos, y son con las que nos vamos a quedar para hacer el estudio reducido y ver si hay mejora al utilizar PCA. Vamos a hacer entonces la combinación lineal que nos da PCA para obtener el nuevo conjunto de train:

```{r}
trainPCA <- apply(pca.out$rotation, 2, function(x) {
  apply(train, 1, function(y) {
    x%*%y
  })
})

trainPCA10 <- apply(pca.out10$rotation, 2, function(x) {
  apply(train10, 1, function(y) {
    x%*%y
  })
})
```

Vamos a hacerle la combinación lineal al conjunto de test también con las componentes principales de train:

```{r}
testPCA <- apply(pca.out$rotation, 2, function(x) {
  apply(test, 1, function(y) {
    x%*%y
  })
})


testPCA10 <- apply(pca.out10$rotation, 2, function(x) {
  apply(test10, 1, function(y) {
    x%*%y
  })
})
```

#4. Normalización de las variables (en su caso).

En el caso de modelos de aprendizaje que trabajan por similaridad, es decir, por distancia entre las muestras para asignar una clase a un dato (como son el KNN y las funciones de base radial) es conveniente normalizar las características de modo que evitemos que unas tengan más peso que otras en las decisiones del modelo, debido a las diferencias de magnitud.

Entonces vamos a normalizar las variables antes de aplicar ningún modelo de aprendizaje para así trabajar con los mismos datos. Entonces vamos a proceder a normalizar los datos, para ello igual que hemos hecho en prácticas anteriores vamos a normalizar los datos de train y empleando los factores de normalización de dicho proceso normalizaremos los de test. De este modo no vamos a contaminar los datos de entrenamiento con información sobre los de test, asegurando que el proceso de aprendizaje se adecuado.

```{r}
train <- scale(train)
medias <- attr(train, "scaled:center")
escalados <- attr(train, "scaled:scale")
test <- scale(test, medias, escalados)

trainPCA <- scale(trainPCA)
medias <- attr(trainPCA, "scaled:center")
escalados <- attr(trainPCA, "scaled:scale")
testPCA <- scale(testPCA, medias, escalados)
```

```{r}
train10 <- scale(train10)
medias <- attr(train10, "scaled:center")
escalados <- attr(train10, "scaled:scale")
test10 <- scale(test10, medias, escalados)

trainPCA10 <- scale(trainPCA10)
medias <- attr(trainPCA10, "scaled:center")
escalados <- attr(trainPCA10, "scaled:scale")
testPCA10 <- scale(testPCA10, medias, escalados)
```


#5. Selección de las técnicas y valoración de la idoneidad de las mismas frente a otras alternativas.

Es claro que no podemos plantearnos usar el perceptron ya que de inicio estamos antes un problema de clasifación no binaria con lo que no vamos a poder realizar una buena clasificación por medio de él.

De entre los modelos paramétricos que hemos visto en la asignatura nos vamos a decantar por la regresión logística multinomial. Podríamos haber considerado el SVM de núcleo lineal pero no conocemos la naturaleza de los datos, con lo cual no tenemos seguridad de vayan a ser linealmente separables, entonces preferimos considerar un modelo el cual no dependa de la disposición espacial de los datos como es la regresión logística.

Por otro lado las funciones de base radial paramétricas no nos parecen una buena opción ya que dependen fuertemente de cómo estén distribuidos los datos, es decir, les ocurre como al KNN; si tenemos puntos próximos al punto a etiquetar de clase distinta a la real del punto entonces la clasificación no será buena. En cambio pensamos que dado que la regresión logística nos da una visión probabilística del etiquetado será más robusta a estas situaciones.

A continuación vamos a explicar cómo funciona la regresion logística multinomial:


#6. Aplicación de las técnicas especificando claramente qué algoritmos se usan en la estimación de los parámetros, los hiperparámetros y el error de generalización.

DISTINGUIR ENTRE SVM Y REGRESIÓN LOGÍSTICA
FARFOLLA
```{r}
classSepMeasure <- function(trainp, clases, numClases) {
  train <- as.matrix(trainp)
  m <- apply(train, 2, sum)/nrow(train)
  mis <- sapply(1:numClases, function(i) {
    datosi <- train[clases==i, ]
    apply(datosi, 2, sum)/nrow(datosi)
  }) 
  n <- 2
  Sw <- matrix(0, n, n)
  for (i in 1:numClases) {
    matriz <- matrix(0, n, n)
    datosi <- train[clases==i, ]
    for(j in 1:nrow(datosi)) {
      matriz_j <- (datosi[j,] - mis[,i])%*%t(datosi[j,] - mis[,i])
      matriz <- matriz + matriz_j
    }
    Sw <- Sw + matriz
  }
  
  Sb <- matrix(0, n, n)
  for (i in 1:numClases) {
    ni <- sum(clases == i)
    Mi <- ni*((mis[,i] - m)%*%t(mis[,i] - m))
    Sb <- Sb + Mi
  }
  
  J <- sum(diag(Sb))/sum(diag(Sw))
  
  return(J)
}
```

```{r}
classSepMeasure(train10, CLASS.train, 10)
```





CON PCA:
EXPLICAR QUÉ HACE CV.GLMNET
EXPLICAR QUÉ HACE GLMNET


```{r}
set.seed(1)
cv.fit <- cv.glmnet(as.matrix(trainPCA), NSP.train, alpha = 0, 
                    family = "multinomial")
lambda <- cv.fit$lambda.min
modeloPCA3 <- glmnet(as.matrix(trainPCA), NSP.train, alpha = 0, 
                     family = "multinomial", lambda = lambda)
predicciones <- predict(modeloPCA3, s=lambda, newx = testPCA, type="response")
```

Esto devuelve para cada nuevo dato la probabilidad de que pertenezca a cada clase. Lo que vamos a hacer ahora es quedarnos con aquella clase a la que corresponda la máxima probabilidad y devolver dicha clase.

```{r}
data <- as.matrix(data.frame(predicciones))
clases.predichas <- apply(data, 1, function(x) {
  which.max(x)
})
cat("Porcentaje de acierto:", 100*sum(clases.predichas == NSP.test)/
      length(NSP.test))
```

Vamos a ver ahora prediciendo con 10 clases:


INCISO A VER SI FUNCIONA Y EL PAQUETE ES TONTO
```{r}
set.seed(1)
clase = 10
train_una_clase = train10[CLASS.train == clase,]
n_datos_clase = nrow(train_una_clase)
train_idx <- sample(which(CLASS.train != clase), n_datos_clase)
train.resto = train10[train_idx,]
train.OVA = rbind(train_una_clase, train.resto)
train.CLASS.OVA = c(rep(1, n_datos_clase), rep(0, n_datos_clase))

test.OVA <- train10[-c(train_idx, which(CLASS.train == clase)), ]

cv.fit <- cv.glmnet(as.matrix(train.OVA), train.CLASS.OVA, alpha = 0, 
                    family = "binomial")
lambda <- cv.fit$lambda.min
modelo <- glmnet(as.matrix(train.OVA), train.CLASS.OVA, alpha = 0, 
                 lambda = lambda, family="binomial")
predicciones <- predict(modelo, s=lambda, newx = test.OVA, type = "response")
data <- as.matrix(data.frame(predicciones))


clases.predichas = rep(0, nrow(test.OVA))
clases.predichas[predicciones > .5] = 1

cat("Porcentaje de acierto:", 100*sum(clases.predichas == 0)/
      nrow(test.OVA))
```









```{r}
set.seed(1)
cv.fit <- cv.glmnet(as.matrix(trainPCA10), CLASS.train, alpha = 0, 
                    family = "multinomial")
lambda <- cv.fit$lambda.min
modeloPCA10 <- glmnet(as.matrix(trainPCA10), CLASS.train, alpha = 0, 
                     family = "multinomial", lambda = lambda)
predicciones <- predict(modeloPCA10, s=lambda, newx = testPCA10, type="response")
data <- as.matrix(data.frame(predicciones))
clases.predichas10 <- apply(data, 1, function(x) {
  which.max(x)
})
```



SIN PCA:

```{r}
set.seed(1)
cv.fit <- cv.glmnet(as.matrix(train10), CLASS.train, alpha = 0, 
                    family = "multinomial")
lambda <- cv.fit$lambda.min
modelo10 <- glmnet(as.matrix(train10), CLASS.train, alpha = 0, 
                     family = "multinomial", lambda = lambda)
predicciones <- predict(modelo10, s=lambda, newx = test10, type="response")
data <- as.matrix(data.frame(predicciones))
clases.predichas10 <- apply(data, 1, function(x) {
  which.max(x)
})
```


NO PARAMÉTRICO:

Vamos a calcular la distancia media de los puntos dentro de una misma clase, y lo vamos a hacer tanto para NSP, donde tenemos 3 clases, como para CLASS, donde tenemos 10, y posteriormente lo vamos a comparar con la distancia media de todos los puntos, para hacernos una idea de si sería mejor utilizar KNN (en el caso de que las distancias medias de cada clase sean pequeñas y más pequeñas que la general) o funciones de base radial no paramétricas (en caso de que esto no sea así).  

Empezamos calculando las distancias medias para las 3 clases que define NSP.

```{r}
getDistanciasMedias <- function(clases, train, numClases) {
  distanciasMedias <- sapply(1:numClases, function(i) {
    if (is.null(clases)) {
      data <- as.matrix(train)
    }
    else {
      data <- which(clases == i)
      data <- as.matrix(train[data,])
    }
    distancia <- rdist(data)
    distMedia <- sum(distancia)/
      (nrow(distancia)*ncol(distancia)- nrow(distancia))
    distMedia
  })
  return(distanciasMedias)
}

```

```{r}
print(getDistanciasMedias(NSP.train, train, 3))
print(getDistanciasMedias(CLASS.train, train10, 10))
print(getDistanciasMedias(NULL, train, 1))
print(getDistanciasMedias(NULL, train10, 1))
```



```{r}
#FUNCIONES DE BASE RADIAL

#Función que devuelve un núcleo Gaussiano normalizado para R^d
fiD <- function(d){
  function(z) {exp(-0.5 * z^2)/((2*pi)^(-d/2))}
}

RBF <- function(x, datos.train, et.train, r) {
  N = nrow(datos.train) #num muestras train
  fi <- fiD(ncol(datos.train))
  alfas = apply(datos.train, 1, function(y) { fi(dist(y,x)/r) } )
  sum(alfas*et.train)/sum(alfas) #g(x)
}
```



#7. Argumentar sobre la idoneidad de la función regularización usada (en su caso).


#8. Valoración de los resultados (gráficas, métricas de error, análisis de residuos, etc.)


#9. Justificar que se ha obtenido la mejor de las posibles soluciones con la técnica elegida y la muestra dada. Argumentar en términos de la dimensión VC del modelo, el error de generalización y las curvas de aprendizaje.



# Bibliografía

\begin{enumerate}
\item La base de datos: \url{https://archive.ics.uci.edu/ml/datasets/Cardiotocography#}
\item PCA con `R`: \url{http://www.r-bloggers.com/computing-and-visualizing-pca-in-r/}
\item Partición de los datos: \href{http://stackoverflow.com/questions/13536537/partitioning-data-set-in-r-based-on-multiple-classes-of-observations}{http://stackoverflow.com/questions/...}
\end{enumerate}
---
title: "Trabajo3"
output: pdf_document
---
```{r, echo=FALSE}
library(MASS)
library(ISLR)
library(class)
library(e1071)
library(ROCR)
set.seed(41192)
attach(Auto) #para no tener que poner el prefijo cada vez que queramo acceder a una atributo del dataframe
```

lm regresión logística por defecto aprende sobre todos, nos devuelve los pesos para cada una de las variables en el orden en el que están disponibles en el dataset, el w0 es el que llaman el Intercept. 

Aquellos que tienen un umbral alto podríamos eliminarlos porque no los creemos, eliminar las columnas que no queremos. Pero aquí lo que podemos hacer de otra forma más cómoda introduciendo una fórmula.

modelo1 <- lm(ym, data=datos)
modelo2 <- lm(ym ~ X1+X2+X3, data=datos) así construimos una solución que sólo tiene en cuenta las variables 1,2 y 3.

Una de las bases de datos con las que vamos a trabajar tiene "más pinta de cuadrática" entonces nos podemos plantear hacerlo del siguiente modo:

modelo3 <- lm(y ~ I(x2^2)+x2) tenemos que poner la palabra reservada I para que interprete correctamente la potencia.

poly() para hacer combinaciones polinómicas.

Puede ocurrir que haya sinergia entre atributos, es decir, que no sean independientes unos de otros, entonces vamos a ver cómo escrbimos una fórmula para que el modelo se ajuste como queremos a los datos que le pasamos.

modeloSinergico <- lm(y ~ x1*x2, data = datos) <=> lm(y ~ x1+x2+x1:x2, data = datos)

Despues de aprender un modelo podemos poner names(modelo) y nos dice los elementos que podemos consultar del modelo.

Lo convertimos a factor, asfactor

tune.knn va probando distintos parámetros y te devuelve el que mejor funciona.

# APARTADO 1

## a) Usar las funciones de R pairs() y boxplot() para investigar la dependencia entre mpg y las otras características. ¿Cuáles de las otras características parece más útil para predecir mpg? Justificar la respuesta.

```{r}
#pairs(Auto)
#pairs(mpg ~ displacement + horsepower + weight)
```

Como podemos ver las "gráficas de dependencias" de mpg con respecto a *displacement*, *horsepower* y *weight* son las gráficas que presentan un patrón más parecido entre ellas indicando que mpg tiene una relación fuerte con estas variables ya que se ajusta a ellas de un modo similar. Por ejemplo si vemos la gráfica con respecto a *acceleration* lo que tenemos es una nube de puntos mucho más dispersa. En cambio estas gráficas si que tienen un aspecto de ser ajustables linealmente.

```{r}
"
boxplot(mpg ~ cylinders)
boxplot(mpg ~ displacement)
boxplot(mpg ~ horsepower)
boxplot(mpg ~ weight)
boxplot(mpg ~ acceleration)
boxplot(mpg ~ year)
boxplot(mpg ~ origin)
boxplot(mpg ~ name)"
```



## b) Seleccionar las variables predictoras que considere más relevantes.

```{r}
datos = Auto[,c("mpg","displacement", "horsepower", "weight")]
```

## c) Particionar el conjunto de datos en un conjunto de entrenamiento (80%) y otro de test (20%). Justificar el procedimiento usado.

A priori había pensado en calcular en primer lugar la variable mpg1 del siguiente apartado para así poder realizar un particionamiento más homogéneo de las etiquetas positivas y negativas en los conjuntos de entrenamiento y test. El problema es que para hacer tal cosa tendría que calcular la mediana de todos los datos de Auto y lo que queremos es calcular la mediana y por tanto el valor de mpg1 sólo en base a los datos de entrenamiento puesto que se dijo en teoría que para no contaminar el aprendizaje no podíamos usar los datos de test para calcular una mediana, sería como mirar los datos antes de aprender. Entonces he realizado simplemente un submuestreo de los datos aleatorio para dividirlos en entrenamiento y test.

```{r}
n = nrow(datos)
idx_train = sample(seq(n), ceiling(0.8*n))

datos.train = datos[idx_train,]
datos.test = datos[-idx_train,]
```
## d) Crear una variable binaria, mpg01, que será igual 1 si la variable mpg contiene un valor por encima de la mediana, y -1 si mpg contiene un valor por debajo de la mediana. La mediana se puede calcular usando la función median(). (Nota: puede resultar útil usar la función data.frames() para unir en un mismo conjunto de datos la nueva variable mpg01 y las otras variables Auto).

```{r}
mediana = median(datos.train$mpg)
mpg1.train = sapply(datos.train$mpg, function(x) if (x < mediana) return(0) else return(1))
mpg1.test = sapply(datos.test$mpg, function(x) if (x < mediana) return(0) else return(1))
```

* Ajustar un modelo de regresión logística a los datos de entrenamiento y predecir mpg01 usando las variables seleccionadas en b). ¿Cuál es el error de test del modelo? Justificar la respuesta.

```{r}
train = data.frame(mpg01 = mpg1.train, datos.train)
test = data.frame(mpg01 = mpg1.test, datos.test)

RL = glm(mpg01 ~ displacement+horsepower+weight, data = train, family = binomial)

prediccion = predict(RL, newdata = test, type = "response")
RL.pred = rep(0, length(test$mpg01))
RL.pred[prediccion > .5] = 1

cat("El número de errores en test con RL es: ", sum(test$mpg01 != RL.pred))

perf = performance(prediccion, "tpr", "fpr")
plot(perf)
```


* Ajustar un modelo K-NN a los datos de entrenamiento y predecir mpg01 usando solamente las variables seleccionadas en b). ¿Cuál es el error de test del modelo? ¿Cuál es el valor de K que mejor ajusta los datos?

```{r}
#normalizamos los datos
train.norm = scale(train[,c("weight","displacement","horsepower")])
medias = attr(train.norm, "scaled:center")
escalados = attr(train.norm, "scaled:scale")
test.norm = scale(test[,c("weight","displacement","horsepower")], medias, escalados)

full.data = rbind(train.norm, test.norm)
full.labels = as.factor(c(mpg1.train,mpg1.test))

set.seed(75570417)
mknns = tune.knn(full.data, full.labels, k=1:20, tunecontrol = tune.control(sampling = "cross"), cross = 10)

mejor_k = mknns$best.model$k

KNN = knn(train.norm, test.norm, train$mpg01, k = mejor_k)

cat("El numero de errores que obtenemos en el test es: ", sum(test$mpg01 != KNN), "\n")
```



Para obtener la curva rho lo que hacemos es:
pred = prediction(modelo, test.label)
perf = performance(pred, "tpr", "fpr")
plot(perf)

El problema que tiene el KNN es que no devuelve un modelo, lo que hemos de hacer es en los argumentos del KNN pasarle prob = TRUE lo cual nos devuelve una probabilidad, pero que realmente es una serie de etiquetas:
0 1 0 1 1 0 1 0
vj = knn(,.........,prob=TRUE)
attributes nos sirve para obtener estos vectores de etiquetas y probabilidades

a lo que sea cero le ponemos 1-probabilidad de que sea cero eso esta en el $prob para poder emplear esta probabilidad para usar performance y luego poder pintar la curva.


para el vaging mtray = ncol-1 de los datos que tenemos (es un random forest)